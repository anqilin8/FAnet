# -*- coding: utf-8 -*-
"""
æ‰¹é‡ï¼šç»çº¬åº¦å»é‡ â†’ è®¡ç®—èŠ‚è¯ç‡ â†’ éšæœºå¤šå…³å–·å¤´ç”Ÿæˆæ–°TXT â†’ è®¡ç®—å‰/åèŠ‚è¯ç‡
- æ‰«æ IN_DIR ä¸‹çš„ .txt/.csv
- å»é‡ï¼šLatitude & Longitude å­—ç¬¦ä¸²å®Œå…¨ç›¸åŒï¼ˆå« N/Eï¼‰â†’ ä¿ç•™é¦–æ¡
- èŠ‚è¯ç‡ï¼š1 - (sum(æ¯è¡ŒZonesé‡Œ1çš„ä¸ªæ•°) / (è®°å½•æ•° * NOZZLE_CNT))
- é¢å¤–éšæœºå…³å–·å¤´ï¼šå¯¹åŸæ¥ä¸º1çš„ä½ç½®ï¼Œä»¥æ¦‚ç‡ EXTRA_OFF_PROB ç½®0ï¼Œå†™ *_dedup_rand.txt
- å…¼å®¹å­—æ®µï¼šä¼˜å…ˆ Zonesï¼›æ— åˆ™å°è¯• Control Signal
"""

import os, glob, re, random

# ====== æ”¹è¿™é‡Œ ======
IN_DIR            = r"E:\conda\weed\runs\64\exp_76"  # ä½ çš„txtæ‰€åœ¨æ–‡ä»¶å¤¹
NOZZLE_CNT        = 6                                     # å–·å¤´æ•°
EXTRA_OFF_PROB    = 0.25                                  # å¯¹åŸæœ¬ä¸º1çš„å–·å¤´é¢å¤–éšæœºå…³çš„æ¦‚ç‡
RANDOM_SEED       = 42                                    # å¤ç°å®éªŒ
OUT_SUFFIX_DEDUP  = "_dedup"                              # å»é‡ååç¼€
OUT_SUFFIX_RAND   = "_dedup_rand"                         # éšæœºå¤šå…³ååç¼€
# =====================

random.seed(RANDOM_SEED)

def split_top_level_commas(line: str):
    """ä»…åœ¨é¡¶å±‚é€—å·å¤„åˆ†å‰²ï¼Œ[] å†…é€—å·ä¸åˆ‡å¼€"""
    parts, buf, depth = [], [], 0
    for ch in line:
        if ch == '[':
            depth += 1; buf.append(ch)
        elif ch == ']':
            depth = max(0, depth - 1); buf.append(ch)
        elif ch == ',' and depth == 0:
            parts.append(''.join(buf).strip()); buf = []
        else:
            buf.append(ch)
    if buf: parts.append(''.join(buf).strip())
    return parts

def parse_header(header_line: str):
    cols = split_top_level_commas(header_line.strip())
    name2idx = {c: i for i, c in enumerate(cols)}
    return cols, name2idx

def find_idx(name2idx, pred):
    for k, i in name2idx.items():
        if pred(k): return i
    return None

def parse_array(field: str):
    """'[0,1,1,0,1,1]' -> [0,1,1,0,1,1]ï¼›å¤±è´¥è¿”å› None"""
    m = re.search(r'\[(.*?)\]', field)
    if not m: return None
    try:
        return [int(x.strip()) for x in m.group(1).split(',') if x.strip()!='']
    except:
        return None

def array_to_str(arr):
    return '[' + ', '.join(str(int(v)) for v in arr) + ']'

def dedup_by_latlon(lines):
    """è¿”å›(è¡¨å¤´, å»é‡åçš„è¡Œåˆ—è¡¨list[str])ï¼›æŒ‰ç»çº¬åº¦å­—ç¬¦ä¸²ç²¾ç¡®å»é‡"""
    if not lines: return "", []
    header = lines[0]
    cols, name2idx = parse_header(header)
    idx_lat = find_idx(name2idx, lambda k: 'latitude'  in k.lower())
    idx_lon = find_idx(name2idx, lambda k: 'longitude' in k.lower())
    if idx_lat is None or idx_lon is None:
        return "", []

    kept = [header]
    seen = set()
    for ln in lines[1:]:
        parts = split_top_level_commas(ln)
        if max(idx_lat, idx_lon) >= len(parts):
            continue
        key = (parts[idx_lat].strip(), parts[idx_lon].strip())
        if key in seen:
            continue
        seen.add(key)
        kept.append(ln)
    return header, kept

def compute_saving_rate(lines, nozzle_cnt=NOZZLE_CNT):
    """æ ¹æ®æ•°ç»„åˆ—(Zonesæˆ–Control Signal)è®¡ç®—èŠ‚è¯ç‡"""
    if not lines or len(lines) <= 1:
        return 0.0, 0, 0
    header = lines[0]
    cols, name2idx = parse_header(header)
    idx_arr = find_idx(name2idx, lambda k: k.strip().lower() == 'zones')
    if idx_arr is None:
        idx_arr = find_idx(name2idx, lambda k: ('control' in k.lower() and 'signal' in k.lower()))
    if idx_arr is None:
        return 0.0, 0, 0

    total_records = 0
    total_on = 0
    for ln in lines[1:]:
        parts = split_top_level_commas(ln)
        if idx_arr >= len(parts):
            continue
        arr = parse_array(parts[idx_arr])
        if arr is None or len(arr) != nozzle_cnt:
            continue
        total_records += 1
        total_on += sum(1 for v in arr if v == 1)
    if total_records == 0:
        return 0.0, 0, 0
    max_on = total_records * nozzle_cnt
    saving = 1.0 - (total_on / max_on)
    return saving, total_records, total_on

def make_random_off_lines(lines, nozzle_cnt=NOZZLE_CNT, extra_off_prob=EXTRA_OFF_PROB):
    """å¯¹åŸæœ¬ä¸º1çš„ä½ç½®ä»¥æ¦‚ç‡ç½®0ï¼Œè¿”å›æ–°è¡Œåˆ—è¡¨ï¼ˆä¿ç•™å…¶ä»–å­—æ®µä¸å˜ï¼Œä»…æ›´æ–°æ•°ç»„åˆ—ï¼‰"""
    if not lines: return []
    header = lines[0]
    cols, name2idx = parse_header(header)
    idx_arr = find_idx(name2idx, lambda k: k.strip().lower() == 'zones')
    if idx_arr is None:
        idx_arr = find_idx(name2idx, lambda k: ('control' in k.lower() and 'signal' in k.lower()))
    if idx_arr is None:
        # æ²¡æœ‰æ•°ç»„åˆ—ï¼Œç›´æ¥è¿”å›åŸæ ·
        return lines[:]

    new_lines = [header]
    for ln in lines[1:]:
        parts = split_top_level_commas(ln)
        if idx_arr >= len(parts):
            new_lines.append(ln)
            continue
        arr = parse_array(parts[idx_arr])
        if arr is None or len(arr) != nozzle_cnt:
            new_lines.append(ln)
            continue
        # ä»…å¯¹åŸä¸º1çš„ä½ä»¥æ¦‚ç‡é¢å¤–å…³æ‰
        arr2 = []
        for v in arr:
            if v == 1 and random.random() < extra_off_prob:
                arr2.append(0)
            else:
                arr2.append(v)
        parts[idx_arr] = array_to_str(arr2)
        new_lines.append(','.join(parts))
    return new_lines

def process_one_file(path):
    base, ext = os.path.splitext(path)
    out_dedup = base + OUT_SUFFIX_DEDUP + ext
    out_rand  = base + OUT_SUFFIX_RAND + ext

    with open(path, 'r', encoding='utf-8', errors='ignore') as f:
        raw_lines = [ln for ln in f.read().splitlines() if ln.strip()]

    # 1) å»é‡
    header, dedup_lines = dedup_by_latlon(raw_lines)
    if not dedup_lines:
        print(f"âŒ å»é‡å¤±è´¥æˆ–æ— æœ‰æ•ˆæ•°æ®ï¼š{os.path.basename(path)}")
        return

    os.makedirs(os.path.dirname(out_dedup) or '.', exist_ok=True)
    with open(out_dedup, 'w', encoding='utf-8') as f:
        f.write('\n'.join(dedup_lines) + '\n')

    # 2) åŸå§‹èŠ‚è¯ç‡
    saving_org, nrec_org, on_org = compute_saving_rate(dedup_lines, NOZZLE_CNT)

    # 3) ç”Ÿæˆâ€œéšæœºå¤šå…³å–·å¤´â€çš„æ–°TXT
    rand_lines = make_random_off_lines(dedup_lines, NOZZLE_CNT, EXTRA_OFF_PROB)
    with open(out_rand, 'w', encoding='utf-8') as f:
        f.write('\n'.join(rand_lines) + '\n')

    # 4) æ–°èŠ‚è¯ç‡
    saving_new, nrec_new, on_new = compute_saving_rate(rand_lines, NOZZLE_CNT)

    print(f"ğŸ“„ {os.path.basename(path)}")
    print(f"   â†’ å»é‡åï¼šè®°å½• {nrec_org}ï¼Œå¼€å¯å–·å¤´æ€»æ•° {on_org} / æœ€å¤§ {nrec_org*NOZZLE_CNT}ï¼ŒèŠ‚è¯ç‡ = {saving_org:.2%}")
    print(f"   â†’ éšæœºå¤šå…³({EXTRA_OFF_PROB:.0%})ï¼šè®°å½• {nrec_new}ï¼Œå¼€å¯å–·å¤´æ€»æ•° {on_new} / æœ€å¤§ {nrec_new*NOZZLE_CNT}ï¼ŒèŠ‚è¯ç‡ = {saving_new:.2%}")
    print(f"   â†’ è¾“å‡ºï¼š{os.path.basename(out_dedup)}ï¼Œ{os.path.basename(out_rand)}")

def main():
    paths = sorted(glob.glob(os.path.join(IN_DIR, '*.txt')) + glob.glob(os.path.join(IN_DIR, '*.csv')))
    if not paths:
        print(f"âŒ ç›®å½•å†…æœªæ‰¾åˆ° .txt/.csvï¼š{IN_DIR}")
        return
    for p in paths:
        process_one_file(p)

if __name__ == '__main__':
    main()
